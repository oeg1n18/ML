{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "using tensorflow you design your own graph and then Tensorflow takes the graph and runs it efficiently using optimized C++ code.Each of the graphs can be broken up into different sections so they can be trained using distribued computing across hundreds of servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform \n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code does not actually perform any computation\n",
    "# It just creates a computation graph with one node.\n",
    "X = tf.Variable(3, name='X')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = X*X*y + y +2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Session initializes the variables and \n",
    "#  evaluates f.\n",
    "with tf.Session() as sess:\n",
    "    X.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the 'Session' is set as the default session. Calling x.initializer.run() is equivalent to calling tf.get_default_session().run(X.initializer)\n",
    "  \n",
    "This makes the code easier to read and automatically closes it at the end of the block.\n",
    "\n",
    "Instead of manually running the initializer for every single variable, you can use the global_variables_initializer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run() #initialize all the variables\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tensorflow program typically split into two parts. The construction and execution phase. The constructino phase typically builds the computation grah representing the ML model and the computations required to train it. \n",
    "\n",
    "The execution phase generallly runs a loop that evaluates a training step repeatedly e.g. one step per mini-batch, gradually improving model parameters.\n",
    "\n",
    "## Managing Graphs\n",
    "any node you create is automatically added to the default graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to manage multiple independent graphs. You can do this by creating a new Graph and temporarily making it the default graph inside a with block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifecycle of a Node Value\n",
    "when you evaluate a node, TensorFlow automatically determines the set of nodes that it depends on and it evaluates these nodes first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "X = w + 2\n",
    "y = X + 5\n",
    "z = X * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) \n",
    "    print(z.eval()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code when evaluating y and z tensorflow will firt find that y depends on X which depends in W and will evaluate W then X then Y. when evaluating Z in the same session it will repeat this process again and re-evaluate W and X before Z. \n",
    " \n",
    "If you want to evaluate y and Z efficiently. You must ask TensorFlow to evaluate both y and z in just one graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val,z_val = sess.run([y,z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every session of tensorflow has its on state and does not share with any other. In distributed TesorFlow variable state is stored on servers and not the sessions so multiple sessions can share the same variables.\n",
    "\n",
    "# Linear Regression with Tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0  4.526\n",
      "1  3.585\n",
      "2  3.521\n",
      "3  3.413\n",
      "4  3.422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.068563  ],\n",
       "       [ 0.82961965],\n",
       "       [ 0.11875178],\n",
       "       [-0.26552707],\n",
       "       [ 0.30569667],\n",
       "       [-0.00450281],\n",
       "       [-0.03932635],\n",
       "       [-0.8998825 ],\n",
       "       [-0.8705388 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "scaler = StandardScaler()\n",
    "scaled_housing = scaler.fit_transform(housing.data)\n",
    "m, n = housing.data.shape\n",
    "\n",
    "# adds bias to all training instances \n",
    "# np.c_ takes rows as arguments turns them into columns and joins the columns together. (adding a column of ones)\n",
    "# np.ones returns an array of ones of a given shape\n",
    "# m is the number of rows in the housing data.\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing.data]\n",
    "\n",
    "# create two tensorflow nodes to hold this data\n",
    "x = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"x\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "print(pd.DataFrame(housing.target.reshape(-1,1)).head())\n",
    "\n",
    "# Defines Theta the weights of the linear regression\n",
    "# theta corresponds to the Normal equation\n",
    "XT = tf.transpose(x)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, x)), XT), y)\n",
    "\n",
    "\n",
    "# Starts session to evaluate the theta node\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "theta_value # weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "* Random_uniform() creates a node in the graph that will generate a tensor containing random values, given its shape and value range\n",
    "\n",
    "* assign() creates a node that will assign a new value to a variable\n",
    "\n",
    "* The main loop executes the training step n_epochs times and every 1-- iterations prints out the current Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 MSE = 7.589863\n",
      "Epoch: 100 MSE = 4.874135\n",
      "Epoch: 200 MSE = 4.81821\n",
      "Epoch: 300 MSE = 4.8120546\n",
      "Epoch: 400 MSE = 4.80947\n",
      "Epoch: 500 MSE = 4.807726\n",
      "Epoch: 600 MSE = 4.8064837\n",
      "Epoch: 700 MSE = 4.805584\n",
      "Epoch: 800 MSE = 4.8049355\n",
      "Epoch: 900 MSE = 4.8044643\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "tf.set_random_seed(42)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Scale the inputs \n",
    "# Add a bias to housing data.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "scaled_housing_data_plus_bias = scaler.fit_transform(housing_data_plus_bias)\n",
    "\n",
    "\n",
    "\n",
    "# Create two constant tensors for inputs. \n",
    "# like multidimensional arrays\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "# Creates a Variable\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "# predictions are input data X multiplied by the weights\n",
    "# Ax = b\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "#Calculate errors\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "# differential of the cost function.\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "# Reassigning the new weights.\n",
    "trainin_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) # initializing the variables.\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch:\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(trainin_op) #automatically evaluates all the dependencies\n",
    "    best_tehta = theta.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autodiff \n",
    "there are efficient and non efficient ways of determining the partial derivatiives aka gradients. The above mathematical method for determining gradients is not always the most efficient. Tensorflow have their own autodiff method to use the best version.   \n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "\n",
    "the gradients function takes an operation in this case mean squared error and a list of variables in this case just theta and creates a list of ops one per variable to compute the gradients of the op with regard to the variable. So the gradients node will compute the gradient vector of the MSE with regards to theta.\n",
    "\n",
    "### Using an Optimizer \n",
    "tensor flow can even provide out of the box optimizers for you e.g. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding Data to the Training Algorithm\n",
    "To implement Mini-batch Gradient Descent we need to replace X and y at every iteration within the next mini-batch. Place holder node will help. they dont perform any computation, just output the data you tell them to output at runtime. They are typically used to pass the training data to Tensorflow at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3)) # can have as many rows as needed. \n",
    "B = A + 5 # add 5 to every value in the tensor A.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]}) # A is a tensor containing 1, 2,3 \n",
    "    B_val_2 = B.eval(feed_dict={A:[[4,5,6],[7,8,9]]}) # A is a 2x3 tensor\n",
    "    \n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['feature_names', 'target', 'data', 'DESCR'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = housing.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of batches:  207\n",
      "optimal weights: \n",
      " [[ 7.6444721e-01]\n",
      " [ 7.7052784e-01]\n",
      " [ 1.4800566e-01]\n",
      " [-2.6099530e-01]\n",
      " [ 3.3200032e-01]\n",
      " [ 8.0285873e-04]\n",
      " [ 1.0851246e-01]\n",
      " [-9.2754668e-01]\n",
      " [-8.8170099e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "\n",
    "# Create Placeholders\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "# Create random weights between -1 and 1\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "#Create predictions\n",
    "y_pred = tf.matmul(X, theta)\n",
    "\n",
    "#Find mse in distance between predicted and actual value\n",
    "errors = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "\n",
    "#Create an optimizer to minimize mse\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "# np.ceil rounds up the decimal to the upper bound e.g. 2.1 - 3.0\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size)) \n",
    "print('number of batches: ', n_batches)\n",
    "\n",
    "# fetching one batch at a time from the disk. \n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    indices = np.random.randint(m, size=batch_size) \n",
    "    X_batch = scaled_housing_data_plus_bias[indices] \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] \n",
    "    return X_batch, y_batch\n",
    "\n",
    "\n",
    "\n",
    "# Grouping all the variables together so they can be initialized at once.\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "    print('optimal weights: \\n', best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  MSE:  8.7217655\n",
      "Epoch:  100  MSE:  5.0438943\n",
      "Epoch:  200  MSE:  4.9185176\n",
      "Epoch:  300  MSE:  4.884096\n",
      "Epoch:  400  MSE:  4.8618846\n",
      "Epoch:  500  MSE:  4.845957\n",
      "Epoch:  600  MSE:  4.8344173\n",
      "Epoch:  700  MSE:  4.826027\n",
      "Epoch:  800  MSE:  4.8199296\n",
      "Epoch:  900  MSE:  4.8154836\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epoch = 1000\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "\n",
    "y_preds = tf.matmul(X, theta, name=\"predictions\")\n",
    "errors = y_preds - y\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as ses:\n",
    "    ses.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch%100 == 0:\n",
    "            print('Epoch: ', epoch, ' MSE: ', mse.eval())\n",
    "            save_path = saver.save(ses, \"models/tensorflow/first_linreg.ckpt\")\n",
    "    \n",
    "        ses.run(training_op)\n",
    "    save_path = saver.save(ses, \"models/tensorflow/my_linmodel_final.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/tensorflow/my_linmodel_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"models/tensorflow/my_linmodel_final.ckpt\")\n",
    "    restored_best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36710906],\n",
       "       [ 0.81807035],\n",
       "       [ 0.15117237],\n",
       "       [-0.17901638],\n",
       "       [ 0.20570967],\n",
       "       [ 0.00744027],\n",
       "       [-0.04182237],\n",
       "       [-0.6743842 ],\n",
       "       [-0.6405658 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Graph and Training Curves\n",
    "above I have been using print to evaluate training but it is not very informative. Better to use tensorboard which runs interactive visualizations in your browser. You need to write variables e.g. training error (mse) to a log directory that tensorboard will read from. You need to use a different log directory every time as otherwise succsseive runs will added all the stats together. Best to include a datetime in the heading to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_log = \"models/tensorflow/tensorboard\"\n",
    "logdir = \"{}/run-{}\".format(root_log, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 1000\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_preds = tf.matmul(X, theta, name=\"predictions\")\n",
    "errors = y_preds - y\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('mse', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100, 9) for Tensor 'X:0', which has shape '(20640, 9)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-251b6e030cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_summary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/olivergrainge/opt/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/olivergrainge/opt/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   4949\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4950\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 4951\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/olivergrainge/opt/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/olivergrainge/opt/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1074\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1076\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1077\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (100, 9) for Tensor 'X:0', which has shape '(20640, 9)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()                                                     # not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
