{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a tensorflow graph and how do you define one?\n",
    "\n",
    "A graph defines a computation without actually completing one. That is done in the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph1 = tf.Graph() # Creates a Graph \n",
    "with graph1.as_default():\n",
    "    var = tf.Variable(32, dtype='float32', name=\"var\")\n",
    "    var2 = tf.Variable(34, dtype='float32', name=\"var2\")\n",
    "    init = tf.global_variables_initializer()\n",
    "    total = tf.add(var, var2, name=\"total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is a Tensorflow session and how do you run one\n",
    "\n",
    "A session is the execution phase where you run some or all of the graph. You first have to initialize all the variables and run the relevant operations. Then you can evaluate the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session(graph=graph1) as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(total)\n",
    "    fin_total = total.eval()\n",
    "   \n",
    "fin_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A linear Regression with GradientDescent optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'feature_names', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_housing_shape:  (20640, 9)\n",
      "targets_sahpe:  (20640, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "housing_data = housing.data\n",
    "housing_targets = housing.target.reshape(-1,1)\n",
    "\n",
    "\n",
    "#Scale the inputs \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data_reg = scaler.fit_transform(housing_data)\n",
    "\n",
    "\n",
    "# in the X data need to add a column of 1's to for the y intercept. \n",
    "m, n = scaled_housing_data_reg.shape\n",
    "scaled_housing_data_reg = np.c_[np.ones((m, 1)), scaled_housing_data_reg]\n",
    "\n",
    "print('scaled_housing_shape: ', scaled_housing_data_reg.shape)\n",
    "print('targets_sahpe: ', housing_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the data lets define the graph\n",
    "lin_reg = tf.Graph()\n",
    "with lin_reg.as_default(): \n",
    "    n_epoch = 1000\n",
    "    \n",
    "    X = tf.Variable(scaled_housing_data_reg, dtype='float32', name=\"X\")\n",
    "    y = tf.Variable(housing_targets, dtype='float32', name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "    y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "    errors = y - y_preds\n",
    "    mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  10.101544\n",
      "MSE:  0.8903759\n",
      "MSE:  0.67388684\n",
      "MSE:  0.63307995\n",
      "MSE:  0.60537\n",
      "MSE:  0.5846682\n",
      "MSE:  0.5690334\n",
      "MSE:  0.5571304\n",
      "MSE:  0.54798543\n",
      "MSE:  0.5408885\n"
     ]
    }
   ],
   "source": [
    "#Lets start the session\n",
    "\n",
    "\n",
    "with tf.Session(graph=lin_reg) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"MSE: \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    fin_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How would you use Mini-batch Gradient Descent for Linear Regression\n",
    "Write a Linear Regression model for the california housing data set using mini-batch gradient descent. This would be useful for distributed computing or if the dataset it too big to fit in RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_housing_shape:  (20640, 9)\n",
      "targets_shape:  (20640, 1)\n"
     ]
    }
   ],
   "source": [
    "print('scaled_housing_shape: ', scaled_housing_data_reg.shape)\n",
    "print('targets_shape: ', housing_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "m, n = scaled_housing_data_reg.shape\n",
    "\n",
    "n_epochs = 10 \n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None,1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "errors = y_preds - y\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_size, batch_index): \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_reg[indices]\n",
    "    y_batch = housing_targets[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0582917 ]\n",
      " [ 0.871823  ]\n",
      " [ 0.11908898]\n",
      " [-0.32261235]\n",
      " [ 0.36294264]\n",
      " [ 0.00272483]\n",
      " [-0.08213932]\n",
      " [-0.7787991 ]\n",
      " [-0.7721297 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_size, batch)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "            \n",
    "                \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving the model\n",
    "***Lets copy the Gradient Descent Model but save it***\n",
    "* The saver object is a tf.train.Saver\n",
    "* syntas for saving a session is. saver_obj.save(sess, 'directory.cpkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Now we have the data lets define the graph\n",
    "n_epoch = 1000\n",
    "\n",
    "X = tf.Variable(scaled_housing_data_reg, dtype='float32', name=\"X\")\n",
    "y = tf.Variable(housing_targets, dtype='float32', name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "errors = y - y_preds\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  9.8185625\n",
      "MSE:  0.72300214\n",
      "MSE:  0.58435875\n",
      "MSE:  0.5677064\n",
      "MSE:  0.556749\n",
      "MSE:  0.54830384\n",
      "MSE:  0.54168737\n",
      "MSE:  0.53643996\n",
      "MSE:  0.5322242\n",
      "MSE:  0.5287885\n"
     ]
    }
   ],
   "source": [
    "#Lets start the session\n",
    "#------- Saver -------------\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"MSE: \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    saver.save(sess, 'models/tensorflow/model.cpkt')\n",
    "    fin_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To restore the model and variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/tensorflow/model.cpkt\n",
      "MSE:  0.5259459\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess: \n",
    "    saver.restore(sess, \"models/tensorflow/model.cpkt\")\n",
    "    print('MSE: ', mse.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Viusalize a Graph and Training Curve for the mini batch gradient descent model in tensorboard.\n",
    "\n",
    "Tensorboard is a visualisation software for stats you provide from your model. you must make your model output it's variables to a specific log. Which tensorboard will read from. every time you run the model it will output to the same log which can mess up visualisations so it is useful to use a datetime in the log title. \n",
    "\n",
    "***Steps***\n",
    "1. add a tf.summary.scalar to give it the parameter to output to the log\n",
    "2. create a tf.summary.Filewriter and give it the log directory and graph \n",
    "3. in the execution phase. every few epochs evaluate the tf.summary.scalar\n",
    "4. Write the result of step 3 to the log. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from datetime import datetime \n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"models/tensorflow/tensorboard/tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = scaled_housing_data_reg.shape\n",
    "\n",
    "n_epochs = 10 \n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None,1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "errors = y_preds - y\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "#-------- steps 1 and 2 ------------------\n",
    "mse_summary = tf.summary.scalar('mse', mse) # the node you are writing to the log\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph()) # A FileWriter that has a directory and the\n",
    "# the graph you want to write from.\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_size, batch_index): \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_reg[indices]\n",
    "    y_batch = housing_targets[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0735905 ]\n",
      " [ 0.8425267 ]\n",
      " [ 0.12584218]\n",
      " [-0.3047448 ]\n",
      " [ 0.29672837]\n",
      " [-0.00408026]\n",
      " [ 0.00807172]\n",
      " [-0.7907821 ]\n",
      " [-0.77579284]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--- Execution ------------\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_size, batch)\n",
    "            if batch%10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X:X_batch, y:y_batch}) #the value to write\n",
    "                step = epoch * n_batches + batch\n",
    "                file_writer.add_summary(summary_str, step) # summary to \n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "file_writer.close() \n",
    "            \n",
    "                \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your directory to see if it has worked.\n",
    "\n",
    "use the following command in your command line: \n",
    "* tensorboard --dirctory/to/logs log_folder/\n",
    "\n",
    "<img src=\"models/tensorflow/tensorboard/model_graphs/california_housing.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Why would you create a name scope and how do you do it for a model? \n",
    "\n",
    "In complex neural networks for example when thousands of nodes are present the graphs can look quite complicated. To avoid this is it benefitial to group certain operations under a single name scope to declutter the graph.\n",
    "\n",
    "lets create one for the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from datetime import datetime \n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"models/tensorflow/tensorboard/tf_logs\"\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = scaled_housing_data_reg.shape\n",
    "\n",
    "n_epochs = 10 \n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None,1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "\n",
    "\n",
    "#-------------- Add name scope ------------------------#\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    errors = y_preds - y\n",
    "    mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "mse_summary = tf.summary.scalar('mse', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_size, batch_index): \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_reg[indices]\n",
    "    y_batch = housing_targets[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n",
      "[[ 2.0649602e+00]\n",
      " [ 8.5481781e-01]\n",
      " [ 1.3767937e-01]\n",
      " [-3.1671110e-01]\n",
      " [ 3.1873599e-01]\n",
      " [ 7.8556128e-04]\n",
      " [-4.6501223e-02]\n",
      " [-8.0104780e-01]\n",
      " [-7.8397709e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--- Execution ------------\n",
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_size, batch)\n",
    "            if batch%10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "                step = epoch * n_batches + batch\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "file_writer.close() \n",
    "            \n",
    "                \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***lets have a look at the new graph with the name scope***\n",
    "\n",
    "<img src=\"models/tensorflow/tensorboard/model_graphs/california_housing_name_scope.png\">\n",
    "\n",
    "***As you can see compared to the graph above the mse and error operation nodes are grouped under Loss***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n"
     ]
    }
   ],
   "source": [
    "print(errors.op.name) # the name of each op is defined within the scope with the prex \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. suppose you wanted to create a graph that outputs the sum of 2 rectified linear units. How would you do it? \n",
    "\n",
    "rectified linear units compute the result of the linear equation and return either the result or 0 depending on which is larger. Hence rectified. writing two different graphs for the same process would be repetative so you can do the following. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\") as scope:\n",
    "        w_shape = (int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"w\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"models/tensorflow/tensorboard/relu3\", tf.get_default_graph())\n",
    "file_writer.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant graph represents three different graphs in the same space showing modularity. \n",
    "\n",
    "<img src=\"models/tensorflow/tensorboard/model_graphs/modularity_relu.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
