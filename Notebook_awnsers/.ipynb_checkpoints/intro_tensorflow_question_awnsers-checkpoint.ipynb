{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a tensorflow graph and how do you define one?\n",
    "\n",
    "A graph defines a computation without actually completing one. That is done in the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "graph1 = tf.Graph() # Creates a Graph \n",
    "with graph1.as_default():\n",
    "    var = tf.Variable(32, dtype='float32', name=\"var\")\n",
    "    var2 = tf.Variable(34, dtype='float32', name=\"var2\")\n",
    "    init = tf.global_variables_initializer()\n",
    "    total = tf.add(var, var2, name=\"total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is a Tensorflow session and how do you run one\n",
    "\n",
    "A session is the execution phase where you run some or all of the graph. You first have to initialize all the variables and run the relevant operations. Then you can evaluate the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session(graph=graph1) as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(total)\n",
    "    fin_total = total.eval()\n",
    "   \n",
    "fin_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A linear Regression with GradientDescent optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['DESCR', 'feature_names', 'data', 'target'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "print(housing.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_housing_shape:  (20640, 9)\n",
      "targets_sahpe:  (20640, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "housing_data = housing.data\n",
    "housing_targets = housing.target.reshape(-1,1)\n",
    "\n",
    "\n",
    "#Scale the inputs \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data_reg = scaler.fit_transform(housing_data)\n",
    "\n",
    "\n",
    "# in the X data need to add a column of 1's to for the y intercept. \n",
    "m, n = scaled_housing_data_reg.shape\n",
    "scaled_housing_data_reg = np.c_[np.ones((m, 1)), scaled_housing_data_reg]\n",
    "\n",
    "print('scaled_housing_shape: ', scaled_housing_data_reg.shape)\n",
    "print('targets_sahpe: ', housing_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the data lets define the graph\n",
    "lin_reg = tf.Graph()\n",
    "with lin_reg.as_default(): \n",
    "    n_epoch = 1000\n",
    "    \n",
    "    X = tf.Variable(scaled_housing_data_reg, dtype='float32', name=\"X\")\n",
    "    y = tf.Variable(housing_targets, dtype='float32', name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "    y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "    errors = y - y_preds\n",
    "    mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  6.004972\n",
      "MSE:  0.9336139\n",
      "MSE:  0.76667595\n",
      "MSE:  0.69735307\n",
      "MSE:  0.6481125\n",
      "MSE:  0.61245173\n",
      "MSE:  0.5865506\n",
      "MSE:  0.5676762\n",
      "MSE:  0.55386424\n",
      "MSE:  0.54369706\n"
     ]
    }
   ],
   "source": [
    "#Lets start the session\n",
    "\n",
    "\n",
    "with tf.Session(graph=lin_reg) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"MSE: \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    fin_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How would you use Mini-batch Gradient Descent for Linear Regression\n",
    "Write a Linear Regression model for the california housing data set using mini-batch gradient descent. This would be useful for distributed computing or if the dataset it too big to fit in RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_housing_shape:  (20640, 9)\n",
      "targets_shape:  (20640, 1)\n"
     ]
    }
   ],
   "source": [
    "print('scaled_housing_shape: ', scaled_housing_data_reg.shape)\n",
    "print('targets_shape: ', housing_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "m, n = scaled_housing_data_reg.shape\n",
    "\n",
    "n_epochs = 10 \n",
    "batch_size = 100 \n",
    "n_batches = int(np.ceil(m/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None,1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "errors = y_preds - y\n",
    "mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(epoch, batch_size, batch_index): \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_reg[indices]\n",
    "    y_batch = housing_targets[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0727584 ]\n",
      " [ 0.8676571 ]\n",
      " [ 0.12582691]\n",
      " [-0.32990158]\n",
      " [ 0.3414494 ]\n",
      " [-0.00861318]\n",
      " [-0.05275913]\n",
      " [-0.8088927 ]\n",
      " [-0.7852054 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: \n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_size, batch)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    \n",
    "            \n",
    "                \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving the model\n",
    "***Lets copy the Gradient Descent Model but save it***\n",
    "* The saver object is a tf.train.Saver\n",
    "* syntas for saving a session is. saver_obj.save(sess, 'directory.cpkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have the data lets define the graph\n",
    "lin_reg = tf.Graph()\n",
    "with lin_reg.as_default(): \n",
    "    n_epoch = 1000\n",
    "    \n",
    "    X = tf.Variable(scaled_housing_data_reg, dtype='float32', name=\"X\")\n",
    "    y = tf.Variable(housing_targets, dtype='float32', name=\"y\")\n",
    "    theta = tf.Variable(tf.random_uniform([n, 1], -1.0, 1.0), dtype='float32', name='theta')\n",
    "    y_preds = tf.matmul(X, theta, name=\"y_preds\")\n",
    "    errors = y - y_preds\n",
    "    mse = tf.reduce_mean(tf.square(errors), name=\"mse\")\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    training_op = optimizer.minimize(mse)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  13.642121\n",
      "MSE:  0.90690404\n",
      "MSE:  0.6575236\n",
      "MSE:  0.6170082\n",
      "MSE:  0.5900125\n",
      "MSE:  0.57041043\n",
      "MSE:  0.5560863\n",
      "MSE:  0.54556197\n",
      "MSE:  0.5377708\n",
      "MSE:  0.5319484\n"
     ]
    }
   ],
   "source": [
    "#Lets start the session\n",
    "#------- Saver -------------\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=lin_reg) as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"MSE: \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    saver.save(sess, '/models/tesorflow')\n",
    "    fin_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
